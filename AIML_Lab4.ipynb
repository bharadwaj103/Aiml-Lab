{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPOS1DMZZiZNKm+1NW6FuZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bharadwaj103/Aiml-Lab/blob/main/AIML_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "v19e29fmT5p8",
        "outputId": "b878ad89-119a-4fb7-bed1-f49c80711204"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/sample_data/california_housing_train.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0f926ffe3b55>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/sample_data/california_housing_train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/sample_data/california_housing_train.csv'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "df = pd.read_csv(\"/content/sample_data/california_housing_train.csv\")\n",
        "df.head()\n",
        "df.info(verbose=True)\n",
        "df.describe(percentiles=[0.1,0.25,0.5,0.75,0.9])\n",
        "df.columns\n",
        "sns.pairplot(df)\n",
        "df['median_house_value'].plot.hist(bins=25,figsize=(8,4))\n",
        "df['median_house_value'].plot.density()\n",
        "df.corr()\n",
        "plt.figure(figsize=(10,7))\n",
        "sns.heatmap(df.corr(),annot=True,linewidths=2)\n",
        "## Y = MX +C where Y is dependent, X is independent features\n",
        "## M is slope, C is intercept\n",
        "l_column = list(df.columns) # Making a list out of column names\n",
        "len_feature = len(l_column) # Length of column vector list\n",
        "l_column, len_feature\n",
        "X = df[l_column[2:len_feature-1]]\n",
        "y = df[l_column[len_feature-1]]\n",
        "print(\"Feature set size:\",X.shape)\n",
        "print(\"Variable set size:\",y.shape)\n",
        "X.head()\n",
        "y.head()\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.2, random_state=123)\n",
        "y_train.shape, y_test.shape, X_train.shape, X_test.shape\n",
        "print(\"Training feature set size:\",X_train.shape)\n",
        "print(\"Test feature set size:\",X_test.shape)\n",
        "print(\"Training variable set size:\",y_train.shape)\n",
        "print(\"Test variable set size:\",y_test.shape)\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn import metrics\n",
        "lm = LinearRegression() # Creating a Linear Regression object 'lm'\n",
        "lm.fit(X_train,y_train) # Fit the linear model on to the 'lm' object itself i.e. no need to set this to another variable\n",
        "print(\"The intercept term of the linear model:\", lm.intercept_)\n",
        "print(\"The coefficients of the linear model:\", lm.coef_)\n",
        "#idict = {'Coefficients':lm.intercept_}\n",
        "#idf = pd.DataFrame(data=idict,index=['Intercept'])\n",
        "cdf = pd.DataFrame(data=lm.coef_, index=X_train.columns, columns=[\"Coefficients\"])\n",
        "#cdf=pd.concat([idf,cdf], axis=0)\n",
        "cdf\n",
        "n=X_train.shape[0]\n",
        "k=X_train.shape[1]\n",
        "dfN = n-k\n",
        "train_pred=lm.predict(X_train)\n",
        "train_error = np.square(train_pred - y_train)\n",
        "sum_error=np.sum(train_error)\n",
        "se=[0,0,0,0,0,0]\n",
        "for i in range(k):\n",
        "    r = (sum_error/dfN)\n",
        "    r = r/np.sum(np.square(X_train[\n",
        "        list(X_train.columns)[i]]-X_train[list(X_train.columns)[i]].mean()))\n",
        "    se[i]=np.sqrt(r)\n",
        "\n",
        "\n",
        "from matplotlib import gridspec\n",
        "fig = plt.figure(figsize=(18, 10))\n",
        "gs = gridspec.GridSpec(2,3)\n",
        "#f, ax = plt.subplots(nrows=1,ncols=len(l), sharey=True)\n",
        "ax0 = plt.subplot(gs[0])\n",
        "ax0.scatter(df[l[0]],df['Price'])\n",
        "ax0.set_title(l[0]+\" vs. Price\", fontdict={'fontsize':20})\n",
        "\n",
        "ax1 = plt.subplot(gs[1])\n",
        "ax1.scatter(df[l[1]],df['Price'])\n",
        "ax1.set_title(l[1]+\" vs. Price\",fontdict={'fontsize':20})\n",
        "\n",
        "ax2 = plt.subplot(gs[2])\n",
        "ax2.scatter(df[l[2]],df['Price'])\n",
        "ax2.set_title(l[2]+\" vs. Price\",fontdict={'fontsize':20})\n",
        "\n",
        "ax3 = plt.subplot(gs[3])\n",
        "ax3.scatter(df[l[3]],df['Price'])\n",
        "ax3.set_title(l[3]+\" vs. Price\",fontdict={'fontsize':20})\n",
        "\n",
        "ax4 = plt.subplot(gs[4])\n",
        "ax4.scatter(df[l[4]],df['Price'])\n",
        "ax4.set_title(l[4]+\" vs. Price\",fontdict={'fontsize':20})\n",
        "print(\"R-squared value of this fit:\",round(metrics.r2_score(y_train,train_pred),3))\n",
        "predictions = lm.predict(X_test)\n",
        "print (\"Type of the predicted object:\", type(predictions))\n",
        "print (\"Size of the predicted object:\", predictions.shape)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"Actual vs. predicted house prices\",fontsize=25)\n",
        "plt.xlabel(\"Actual test set house prices\",fontsize=18)\n",
        "plt.ylabel(\"Predicted house prices\", fontsize=18)\n",
        "plt.scatter(x=y_test,y=predictions)\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"Histogram of residuals to check for normality\",fontsize=25)\n",
        "plt.xlabel(\"Residuals\",fontsize=18)\n",
        "plt.ylabel(\"Kernel density\", fontsize=18)\n",
        "sns.histplot([y_test-predictions])\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.title(\"Residuals vs. predicted values plot (Homoscedasticity)\\n\",fontsize=25)\n",
        "plt.xlabel(\"Predicted house prices\",fontsize=18)\n",
        "plt.ylabel(\"Residuals\", fontsize=18)\n",
        "plt.scatter(x=predictions,y=y_test-predictions)\n",
        "print(\"Mean absolute error (MAE):\", metrics.mean_absolute_error(y_test,predictions))\n",
        "print(\"Mean square error (MSE):\", metrics.mean_squared_error(y_test,predictions))\n",
        "print(\"Root mean square error (RMSE):\", np.sqrt(metrics.mean_squared_error(y_test,predictions)))\n",
        "print(\"R-squared value of predictions:\",round(metrics.r2_score(y_test,predictions),3))\n",
        "#compute minmax value for observed price and expected price\n",
        "import numpy as np\n",
        "min=np.min(predictions/6000)\n",
        "max=np.max(predictions/12000)\n",
        "print(min, max)\n",
        "#Compute MinMax value for Price=100\n",
        "L = (100 - min)/(max - min)\n",
        "L\n",
        "plt.hist(L)"
      ]
    }
  ]
}